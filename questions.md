---
layout: page
title: Questions
permalink: /questions/
---

The following is a list of questions that I'm curious about. If you believe you
could share some insight about the answers, please let me know!

  1. What are the highest-leverage applications of machine learning for accelerating science?
  2. How can we perform unsupervised object detection/discovery given large amounts of observational data?
  3. How can we tokenize volumetric representations (NeRFs, splats, etc) as input to LLMs?
  4. What are unique data sources or formats that people aren't yet feeding into LLMs?
  5. Cross-modality world knowledge transfer: If you take a VLM and retrain it with extra textual QA data covering facts about giraffes, will it become a better giraffe detector in images? How does world knowledge from text impact vision-grounded tasks? How can we better utilize textual world knowledge for perception tasks?
  6. How can we generate sparse, hierarchical scene representations directly from images without labeling the hierarchy? For example, convert multiview images into a sparse set of object embeddings which are themselves decoded into 3D Gaussian Splats or NeRFs?
  7. How can scene reconstruction methods like 3DGS or NeRF better utilize the repeated structures in the scene? For example, flowers are made of many similar petals and a brick wall is made of many similar bricks.
